# -*- coding: utf-8 -*-
"""Assignment_CenterMask.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y8IAQF0kTaf1G1i1OPG-X7M2NEJmaTu5

**Research Topics in Computer Vision :: Evaluating the CenterMask**
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pyyaml==5.1
!gcc --version

!git clone https://github.com/facebookresearch/detectron2 detectron2_repo
!pip install -e detectron2_repo

!git clone https://github.com/youngwanLEE/centermask2.git

import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

import matplotlib.pyplot as plt
import os, json, cv2, random
import numpy as np
import cv2
from google.colab.patches import cv2_imshow

from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2_repo.projects import TensorMask
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
from detectron2.data.datasets import register_coco_instances

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/centermask2
from centermask.config import get_cfg
!wget https://dl.dropbox.com/s/tczecsdxt10uai5/centermask2-V-39-eSE-FPN-ms-3x.pth

cfg = get_cfg()
# add_tensormask_config(cfg)
cfg.merge_from_file("/content/centermask2/configs/centermask/centermask_V_39_eSE_FPN_ms_3x.yaml")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model
cfg.MODEL.WEIGHTS = "/content/centermask2/centermask2-V-39-eSE-FPN-ms-3x.pth"
predictor = DefaultPredictor(cfg)

"""***Registering the Coco Validation 2017 Set***"""

register_coco_instances("coco_val", {}, "/content/drive/MyDrive/instances_val2017.json", "/content/drive/MyDrive/val2017")
dataset_dicts = DatasetCatalog.get("coco_val")
cocoval_metadata = MetadataCatalog.get("coco_val")

"""***Registering the Tiny Voc Training Set***"""

register_coco_instances("tiny_voc_train", {}, "/content/drive/MyDrive/tiny_voc_coco_train.json", "/content/drive/MyDrive/voc_train_images")
dataset_dicts = DatasetCatalog.get("tiny_voc_train")
cocoval_metadata = MetadataCatalog.get("tiny_voc_train")

for d in random.sample(dataset_dicts, 3):
    im = cv2.imread(d["file_name"])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=cocoval_metadata,
                   scale=0.5, 
                   instance_mode=ColorMode.IMAGE_BW
    )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])

"""***Performing Evaluation on Coco Validation 2017 Set***"""

evaluator = COCOEvaluator("coco_val", ("bbox", "segm"), False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "coco_val")
print(inference_on_dataset(predictor.model, val_loader, evaluator))

"""***Performing Evaluation on the Tiny Voc Training Dataset***"""

evaluator = COCOEvaluator("tiny_voc_train", ("bbox", "segm"), False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "tiny_voc_train")
print(inference_on_dataset(predictor.model, val_loader, evaluator))