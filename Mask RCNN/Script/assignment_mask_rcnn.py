# -*- coding: utf-8 -*-
"""Assignment_Mask_RCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17klo-d7dSqW54DYVTh_lHEvi_T47V_r2

**Research Topics in Computer Vision :: Evaluating the Mask RCNN**
"""

from google.colab import drive                # Mounting Google Drive that contains the datasets and annotations
drive.mount('/content/drive')

import torch, torchvision                     # Installing Detectron 2 and its dependencies
assert torch.__version__.startswith("1.8")   
!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html

!pip install pyyaml==5.1                  
!gcc --version

import numpy as np                                 # Importing necessary python libraries
import os, json, cv2, random
from google.colab.patches import cv2_imshow

import detectron2                                  # Importing Detectron2 libraries
from detectron2.utils.logger import setup_logger
setup_logger()
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor, DefaultTrainer
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.data.datasets import register_coco_instances
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

cfg = get_cfg()                                         # Getting Mask RCNN modeland weights with the Resnet 101 backend
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml"))
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5             # Setting threshold for this model to 0.5
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml")
predictor = DefaultPredictor(cfg)

"""***Registering the Coco Instances Validation 2017 Dataset***

"""

register_coco_instances("coco_val", {}, "/content/drive/MyDrive/instances_val2017.json", "/content/drive/MyDrive/val2017")
dataset_dicts = DatasetCatalog.get("coco_val")         
cocoval_metadata = MetadataCatalog.get("coco_val")

"""***Registering the Tiny Voc Coco Train Dataset***"""

register_coco_instances("tiny_voc_train", {}, "/content/drive/MyDrive/tiny_voc_coco_train.json", "/content/drive/MyDrive/voc_train_images")
dataset_dicts = DatasetCatalog.get("tiny_voc_train")         
cocoval_metadata = MetadataCatalog.get("tiny_voc_train")

for d in random.sample(dataset_dicts, 3):               # Getting 3 samples from the dataset and perform inference to verify setting up
    im = cv2.imread(d["file_name"])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=cocoval_metadata,
                   scale=0.5, 
                   instance_mode=ColorMode.IMAGE_BW
    )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])

"""***Evaluating the Coco Validation 2017 Dataset with respect to bounding boxes and segmentation masks***"""

evaluator = COCOEvaluator("coco_val", ("bbox", "segm"), False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "coco_val")             # Perform Evaluation on Dataset given
print(inference_on_dataset(predictor.model, val_loader, evaluator))

"""***Evaluating the Tiny Voc Train Dataset with respect to bounding boxes and segmentation masks***"""

evaluator = COCOEvaluator("tiny_voc_train", ("bbox", "segm"), False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "tiny_voc_train")             # Perform Evaluation on Dataset given
print(inference_on_dataset(predictor.model, val_loader, evaluator))