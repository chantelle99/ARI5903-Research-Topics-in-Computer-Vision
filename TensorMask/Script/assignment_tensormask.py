# -*- coding: utf-8 -*-
"""Assignment_TensorMask.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sGz_App0_AM2ZwY-mEEVAHfwn15TKgBo

**Research Topics in Computer Vision :: Evaluating the TensorMask**
"""

from google.colab import drive
drive.mount('/content/drive')

import torch, torchvision
assert torch.__version__.startswith("1.8")   
!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html

!pip install pyyaml==5.1
!gcc --version

!git clone https://github.com/facebookresearch/detectron2 detectron2_repo
!pip install -e detectron2_repo
!pip install -e /content/detectron2_repo/projects/TensorMask

import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

import matplotlib.pyplot as plt
import os, json, cv2, random
import numpy as np
import cv2
from google.colab.patches import cv2_imshow

from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2_repo.projects import TensorMask
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
from detectron2.data.datasets import register_coco_instances

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/detectron2_repo/projects/TensorMask
from tensormask import add_tensormask_config

cfg = get_cfg()
add_tensormask_config(cfg)
cfg.merge_from_file("/content/detectron2_repo/projects/TensorMask/configs/tensormask_R_50_FPN_6x.yaml")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model
cfg.MODEL.WEIGHTS = "/content/drive/MyDrive/model_final_e8df31.pkl"
predictor = DefaultPredictor(cfg)

"""***Registering the Coco Validation 2017 Set***"""

register_coco_instances("coco_val", {}, "/content/drive/MyDrive/instances_val2017.json", "/content/drive/MyDrive/val2017")
dataset_dicts = DatasetCatalog.get("coco_val")
cocoval_metadata = MetadataCatalog.get("coco_val")

"""***Registering the Tiny Voc Training Set***"""

register_coco_instances("tiny_voc_train", {}, "/content/drive/MyDrive/tiny_voc_coco_train.json", "/content/drive/MyDrive/voc_train_images")
dataset_dicts = DatasetCatalog.get("tiny_voc_train")
cocoval_metadata = MetadataCatalog.get("tiny_voc_train")

for d in random.sample(dataset_dicts, 3):
    im = cv2.imread(d["file_name"])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=cocoval_metadata,
                   scale=0.5, 
                   instance_mode=ColorMode.IMAGE_BW
    )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])

"""***Performing Evaluation on Coco Validation 2017 Set***"""

evaluator = COCOEvaluator("coco_val", ("bbox", "segm"), False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "coco_val")
print(inference_on_dataset(predictor.model, val_loader, evaluator))

"""***Performing Evaluation on the Tiny Voc Training Dataset***"""

evaluator = COCOEvaluator("tiny_voc_train", ("bbox", "segm"), False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "tiny_voc_train")
print(inference_on_dataset(predictor.model, val_loader, evaluator))